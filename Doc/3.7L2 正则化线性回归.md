岭回归（**Ridge Regression**），又称为**L2 正则化线性回归**，是在线性回归的基础上加入了一个*
*惩罚项（正则项）**的回归方法，用于防止模型**过拟合**，尤其是在特征数量多或存在多重共线性的情况下。

---

## 一、为什么需要岭回归？

### 🔍 线性回归的问题

普通最小二乘线性回归（OLS）求解的是：

$$
\hat{\beta} = \arg\min_\beta \sum_{i=1}^{n}(y_i - \mathbf{x}_i^\top \beta)^2
$$

这种方法在以下几种情况下容易出现问题：

* 特征高度相关（多重共线性）；
* 特征数量远大于样本数量（n << p）；
* 过拟合：训练集表现好，测试集表现差。

---

## 二、岭回归的原理

岭回归通过在损失函数中加入一个正则项（L2范数）来控制模型复杂度：

$$
\hat{\beta}_{ridge} = \arg\min_\beta \left( \sum_{i=1}^{n}(y_i - \mathbf{x}_i^\top \beta)^2 + \lambda \sum_{j=1}^{p} \beta_j^2 \right)
$$

其中：

* $\lambda \geq 0$ 是正则化强度，称为“岭参数”；
* $\sum \beta_j^2$ 是所有回归系数平方和，称为 L2 正则化项。

### ✅ 目的：

* 控制模型参数的大小；
* 缓解多重共线性；
* 提升泛化能力。

---

## 三、岭回归与线性回归对比

| 特点    | 普通线性回归   | 岭回归（Ridge）       |
|-------|----------|------------------|
| 正则项   | 无        | L2 正则项           |
| 目标函数  | 最小化残差平方和 | 最小化残差平方和 + L2 范数 |
| 参数稳定性 | 对共线性敏感   | 更稳定              |
| 用于降维  | 否        | 可以（配合 PCA）       |

---

## 四、岭回归的数学解

岭回归具有封闭解（closed-form solution）：

$$
\hat{\beta}_{ridge} = (X^\top X + \lambda I)^{-1} X^\top y
$$

其中：

* $X$ 是设计矩阵（特征矩阵）；
* $y$ 是目标向量；
* $I$ 是单位矩阵。

注意：这个解只有当 $X^\top X + \lambda I$ 是可逆矩阵时才成立（加入 $\lambda I$ 就确保了可逆性）。

---

## 五、Python 实现示例（使用 Sklearn）

```python
import numpy as np
from sklearn.linear_model import Ridge
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

# 构造简单数据（y = 3x + noise）
np.random.seed(42)
X = 2 * np.random.rand(100, 1)
y = 3 * X[:, 0] + np.random.randn(100)

# 拆分数据集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# 创建岭回归模型，alpha 是正则化强度
ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)

# 预测与评估
y_pred = ridge.predict(X_test)
print("均方误差（MSE）:", mean_squared_error(y_test, y_pred))
print("模型系数:", ridge.coef_)
print("截距:", ridge.intercept_)
```

---

## 六、与 Lasso 回归的区别

| 对比点  | Ridge（岭回归）   | Lasso（套索回归）           |
|------|--------------|-----------------------|
| 正则类型 | L2 正则化（平方和）  | L1 正则化（绝对值和）          |
| 特征选择 | 不能产生稀疏系数     | 可以将部分系数压缩为 0，具备特征选择能力 |
| 求解难度 | 有解析解，易求      | 通常需迭代优化               |
| 用途偏好 | 多特征共线性，防止过拟合 | 需要进行特征选择的模型           |

---

## 七、总结

* 岭回归是**带 L2 正则项的线性回归**；
* 可用于处理**多重共线性**和**高维数据**；
* 在保留所有特征的前提下**抑制模型过拟合**；
* 正则化强度 $\lambda$ 是调节模型的关键超参数，可通过交叉验证确定。

---
